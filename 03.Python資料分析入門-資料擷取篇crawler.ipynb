{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "這章節主要是為了帶領大家玩資料，會有一些實用的爬蟲，然後用案例無壓力地慢慢拆解唷"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.資料擷取"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "取得資料有幾種方式\n - 已經整理好的資料集，如政府資料開放平台[OpenData](https://data.gov.tw/)\n - 用該網頁的API（像是googlemap API）\n - 直接用爬蟲擷取網站\n   - 擷取網站又有分靜態網站可以輕易地擷取，也有網站資料寫在AJAX不容易擷取的(超出本次課程範圍)，以下用常用的社群媒體及新聞網站資料做介紹。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 1-1 PTT個版文章搜尋"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "台灣最大BBS交流平台PTT已經有網頁版本，而且規律的結構、熱門的討論很適合做案例分析。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport requests \nfrom bs4 import BeautifulSoup",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "board ='NBA' #版名，也可以嘗試movie、Beauty、TaichungBun等板\nurl = 'https://www.ptt.cc/bbs/'+board+'/index.html'\n\nresponse = requests.get(url)\nhtml_doc = response.text # text 屬性就是 html 檔案\nsoup = BeautifulSoup(response.text, \"lxml\") # 指定 lxml 作為解析器\n\nauthor_ids = []  # 建立一個空的 list 來放作者 id\nrecommends = []  # 建立一個空的 list 來放推文數\npost_titles = [] # 建立一個空的 list 來放文章標題\npost_dates = []  # 建立一個空的 list 來放發文日期\n\nposts = soup.find_all(\"div\", class_ = \"r-ent\")\nfor post in posts:\n    try:\n        author_ids.append(post.find(\"div\", class_ = \"author\").string)    \n    except:\n        author_ids.append(np.nan)\n    try:\n        post_titles.append(post.find(\"a\").string)\n    except:\n        post_titles.append(np.nan)\n    try:\n        post_dates.append(post.find(\"div\", class_ = \"date\").string)\n    except:\n        post_dates.append(np.nan)\n\n# 推文數藏在 div 裡面的 span 所以分開處理\nrecommendations = soup.find_all(\"div\", class_ = \"nrec\")\nfor recommendation in recommendations:\n    try:\n        recommends.append(int(recommendation.find(\"span\").string))\n    except:\n        recommends.append(np.nan)\n        \nptt_dict = {\"author\": author_ids,\n                \"recommends\": recommends,\n                \"title\": post_titles,\n                \"date\": post_dates\n}\n\nptt_df = pd.DataFrame(ptt_dict)\nptt_df",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>date</th>\n      <th>recommends</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ericf129</td>\n      <td>4/18</td>\n      <td>24.0</td>\n      <td>[公告] NBA 板 開始舉辦樂透!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MrSatan</td>\n      <td>4/18</td>\n      <td>27.0</td>\n      <td>Re: [新聞] 詹姆斯第四度入選 時代百大唯一籃球員</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pneumo</td>\n      <td>4/18</td>\n      <td>68.0</td>\n      <td>[花邊] James Harden晃飛Rubio後抖肩...但沒進</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>huntai</td>\n      <td>4/18</td>\n      <td>8.0</td>\n      <td>Re: [花邊] 狀元不選Zion？West：那就像錯過MJ一樣</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LeBronJame23</td>\n      <td>4/18</td>\n      <td>3.0</td>\n      <td>Re: [花邊] 狀元不選Zion？West：那就像錯過MJ一樣</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>namie810303</td>\n      <td>4/07</td>\n      <td>80.0</td>\n      <td>[公告] 季後賽期間條款</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Vedan</td>\n      <td>4/08</td>\n      <td>NaN</td>\n      <td>[公告] 板規v6.3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>JerroLi</td>\n      <td>4/12</td>\n      <td>21.0</td>\n      <td>[情報] Playoff Schedule 18–19</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ericf129</td>\n      <td>4/18</td>\n      <td>28.0</td>\n      <td>[公告] NBA 板 開始舉辦樂透!</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "         author   date  recommends                              title\n0      ericf129   4/18        24.0                 [公告] NBA 板 開始舉辦樂透!\n1       MrSatan   4/18        27.0        Re: [新聞] 詹姆斯第四度入選 時代百大唯一籃球員\n2        pneumo   4/18        68.0  [花邊] James Harden晃飛Rubio後抖肩...但沒進\n3        huntai   4/18         8.0   Re: [花邊] 狀元不選Zion？West：那就像錯過MJ一樣\n4  LeBronJame23   4/18         3.0   Re: [花邊] 狀元不選Zion？West：那就像錯過MJ一樣\n5   namie810303   4/07        80.0                       [公告] 季後賽期間條款\n6         Vedan   4/08         NaN                        [公告] 板規v6.3\n7       JerroLi   4/12        21.0        [情報] Playoff Schedule 18–19\n8      ericf129   4/18        28.0                 [公告] NBA 板 開始舉辦樂透!"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 1-2 PTT個版搜尋-方法2"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport time\nimport json\nfrom bs4 import BeautifulSoup\n\n\nPTT_URL = 'https://www.ptt.cc'\n\ndef get_web_page(url):\n    resp = requests.get(\n        url=url,\n        cookies={'over18': '1'}  # 告知Server已回答過滿18歲的問題\n    )\n    if resp.status_code != 200:\n        print('Invalid url:', resp.url)\n        return None\n    else:\n        return resp.text\n\n\ndef get_articles(dom, date):\n    soup = BeautifulSoup(dom, 'html5lib')\n\n    # 取得上一頁的連結\n    paging_div = soup.find('div', 'btn-group btn-group-paging')\n    prev_url = paging_div.find_all('a')[1]['href']\n\n    articles = []  # 儲存取得的文章資料\n    divs = soup.find_all('div', 'r-ent')\n    for d in divs:\n        if d.find('div', 'date').text.strip() == date:  # 發文日期正確\n            # 取得推文數\n            push_count = 0\n            push_str = d.find('div', 'nrec').text\n            if push_str:\n                try:\n                    push_count = int(push_str)  # 轉換字串為數字\n                except ValueError:\n                    # 若轉換失敗，可能是'爆'或 'X1', 'X2', ...\n                    # 若不是, 不做任何事，push_count 保持為 0\n                    if push_str == '爆':\n                        push_count = 99\n                    elif push_str.startswith('X'):\n                        push_count = -10\n\n            # 取得文章連結及標題\n            if d.find('a'):  # 有超連結，表示文章存在，未被刪除\n                href = d.find('a')['href']\n                title = d.find('a').text\n                author = d.find('div', 'author').text if d.find('div', 'author') else ''\n                articles.append({\n                    'title': title,\n                    'href': href,\n                    'push_count': push_count,\n                    'author': author\n                })\n    return articles, prev_url\n\n\ndef get_author_ids(posts, pattern):\n    ids = set()\n    for post in posts:\n        if pattern in post['author']:\n            ids.add(post['author'])\n    return ids\n\n\nif __name__ == '__main__':\n    board ='Gossiping' #版名，也可以嘗試movie、Beauty、TaichungBun等板\n    current_page = get_web_page(PTT_URL + '/bbs/'+board+'/index.html')\n    if current_page:\n        articles = []  # 全部的今日文章\n        today = time.strftime(\"%m/%d\").lstrip('0')  # 今天日期, 去掉開頭的 '0' 以符合 PTT 網站格式\n        current_articles, prev_url = get_articles(current_page, today)  # 目前頁面的今日文章\n        while current_articles:  # 若目前頁面有今日文章則加入 articles，並回到上一頁繼續尋找是否有今日文章\n            articles += current_articles\n            current_page = get_web_page(PTT_URL + prev_url)\n            current_articles, prev_url = get_articles(current_page, today)\n\n        # 印出所有不同的 5566 id\n#         print(get_author_ids(articles, '5566'))\n\n        # 儲存或處理文章資訊\n        print('今天有', len(articles), '篇文章')\n        threshold = 98\n        print('熱門文章(> %d 推):' % (threshold))\n        for a in articles:\n            if int(a['push_count']) > threshold:\n                print(a)\n        with open('./data/gossiping.json', 'w', encoding='utf-8') as f:\n            json.dump(articles, f, indent=2, sort_keys=True, ensure_ascii=False)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "今天有 401 篇文章\n熱門文章(> 98 推):\n{'title': '[新聞] 外媒看衰？那些年 郭台銘從沒兌現的承諾', 'href': '/bbs/Gossiping/M.1555570420.A.BAF.html', 'push_count': 99, 'author': 'Gocoba'}\n{'title': '[新聞] 氣象局：非正常能量釋放 周內恐有規', 'href': '/bbs/Gossiping/M.1555568984.A.E22.html', 'push_count': 99, 'author': 'justice2008'}\n{'title': '[問卦] 《與惡》是不是完全貼切描述台灣媒體現況', 'href': '/bbs/Gossiping/M.1555567330.A.845.html', 'push_count': 99, 'author': 'Bjergsen'}\n{'title': '[臉書] 蔡英文', 'href': '/bbs/Gossiping/M.1555567874.A.DAB.html', 'push_count': 99, 'author': 'ptt12'}\n{'title': '[爆卦] 宿舍484要倒了?', 'href': '/bbs/Gossiping/M.1555565732.A.80B.html', 'push_count': 99, 'author': 'stan871125'}\n{'title': 'Re: [爆卦] 馬路裂開了', 'href': '/bbs/Gossiping/M.1555565597.A.E3E.html', 'push_count': 99, 'author': 'killeryuan'}\n{'title': '[爆卦] 馬路裂開了（誤傳）柏油灑落（O)', 'href': '/bbs/Gossiping/M.1555565036.A.CCF.html', 'push_count': 99, 'author': 'Abet'}\n{'title': '[問卦] 這次地震有多少人真的有恐懼感的', 'href': '/bbs/Gossiping/M.1555564529.A.675.html', 'push_count': 99, 'author': 'misaka10032'}\n{'title': '[問卦] 簡訊先來的舉手', 'href': '/bbs/Gossiping/M.1555564313.A.F3F.html', 'push_count': 99, 'author': 'syxuan'}\n{'title': '[問卦] 簡訊通知呢?', 'href': '/bbs/Gossiping/M.1555563861.A.E00.html', 'push_count': 99, 'author': 'ice0110'}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ptt_df = pd.DataFrame(articles)\nfilter = ptt_df[\"push_count\"] > 98\nptt_df[filter]",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>href</th>\n      <th>push_count</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>83</th>\n      <td>Gocoba</td>\n      <td>/bbs/Gossiping/M.1555570420.A.BAF.html</td>\n      <td>99</td>\n      <td>[新聞] 外媒看衰？那些年 郭台銘從沒兌現的承諾</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>justice2008</td>\n      <td>/bbs/Gossiping/M.1555568984.A.E22.html</td>\n      <td>99</td>\n      <td>[新聞] 氣象局：非正常能量釋放 周內恐有規</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>Bjergsen</td>\n      <td>/bbs/Gossiping/M.1555567330.A.845.html</td>\n      <td>99</td>\n      <td>[問卦] 《與惡》是不是完全貼切描述台灣媒體現況</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>ptt12</td>\n      <td>/bbs/Gossiping/M.1555567874.A.DAB.html</td>\n      <td>99</td>\n      <td>[臉書] 蔡英文</td>\n    </tr>\n    <tr>\n      <th>240</th>\n      <td>stan871125</td>\n      <td>/bbs/Gossiping/M.1555565732.A.80B.html</td>\n      <td>99</td>\n      <td>[爆卦] 宿舍484要倒了?</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>killeryuan</td>\n      <td>/bbs/Gossiping/M.1555565597.A.E3E.html</td>\n      <td>99</td>\n      <td>Re: [爆卦] 馬路裂開了</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>Abet</td>\n      <td>/bbs/Gossiping/M.1555565036.A.CCF.html</td>\n      <td>99</td>\n      <td>[爆卦] 馬路裂開了（誤傳）柏油灑落（O)</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>misaka10032</td>\n      <td>/bbs/Gossiping/M.1555564529.A.675.html</td>\n      <td>99</td>\n      <td>[問卦] 這次地震有多少人真的有恐懼感的</td>\n    </tr>\n    <tr>\n      <th>354</th>\n      <td>syxuan</td>\n      <td>/bbs/Gossiping/M.1555564313.A.F3F.html</td>\n      <td>99</td>\n      <td>[問卦] 簡訊先來的舉手</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>ice0110</td>\n      <td>/bbs/Gossiping/M.1555563861.A.E00.html</td>\n      <td>99</td>\n      <td>[問卦] 簡訊通知呢?</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "          author                                    href  push_count  \\\n83        Gocoba  /bbs/Gossiping/M.1555570420.A.BAF.html          99   \n133  justice2008  /bbs/Gossiping/M.1555568984.A.E22.html          99   \n179     Bjergsen  /bbs/Gossiping/M.1555567330.A.845.html          99   \n195        ptt12  /bbs/Gossiping/M.1555567874.A.DAB.html          99   \n240   stan871125  /bbs/Gossiping/M.1555565732.A.80B.html          99   \n271   killeryuan  /bbs/Gossiping/M.1555565597.A.E3E.html          99   \n276         Abet  /bbs/Gossiping/M.1555565036.A.CCF.html          99   \n340  misaka10032  /bbs/Gossiping/M.1555564529.A.675.html          99   \n354       syxuan  /bbs/Gossiping/M.1555564313.A.F3F.html          99   \n395      ice0110  /bbs/Gossiping/M.1555563861.A.E00.html          99   \n\n                        title  \n83   [新聞] 外媒看衰？那些年 郭台銘從沒兌現的承諾  \n133    [新聞] 氣象局：非正常能量釋放 周內恐有規  \n179  [問卦] 《與惡》是不是完全貼切描述台灣媒體現況  \n195                  [臉書] 蔡英文  \n240            [爆卦] 宿舍484要倒了?  \n271            Re: [爆卦] 馬路裂開了  \n276     [爆卦] 馬路裂開了（誤傳）柏油灑落（O)  \n340      [問卦] 這次地震有多少人真的有恐懼感的  \n354              [問卦] 簡訊先來的舉手  \n395               [問卦] 簡訊通知呢?  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def ptt_hot():\n    target_url = 'http://disp.cc/b/PttHot'\n    print('Start parsing pttHot....')\n    rs = requests.session()\n    res = rs.get(target_url, verify=False)\n    soup = BeautifulSoup(res.text, 'html.parser')\n    content = \"\"\n    for data in soup.select('#list div.row2 div span.listTitle'):\n        title = data.text\n        link = \"http://disp.cc/b/\" + data.find('a')['href']\n        if data.find('a')['href'] == \"796-59l9\":\n            break\n        content += '{} {}\\n'.format(title, link)\n    return content\n\npd.DataFrame(ptt_hot().split(\"\\n\")).head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Start parsing pttHot....\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>■ [新聞] 文化瑰寶付之一炬！《刺客教條》遊戲內容將有助重建 http://disp.cc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>■ [問卦] 標太郎水餃告訴大眾 切勿相信網路謠言 http://disp.cc/b/796...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>■ [爆卦] 政經造反啦！！！ http://disp.cc/b/796-b35p</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>■ [閒聊] 閃耀暖暖-長得醜錯了嗎QQ http://disp.cc/b/796-bdE7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>■ Re: [問卦] 蜂蜜快到期了 該怎辦？(附圖) http://disp.cc/b/79...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                   0\n0  ■ [新聞] 文化瑰寶付之一炬！《刺客教條》遊戲內容將有助重建 http://disp.cc...\n1  ■ [問卦] 標太郎水餃告訴大眾 切勿相信網路謠言 http://disp.cc/b/796...\n2          ■ [爆卦] 政經造反啦！！！ http://disp.cc/b/796-b35p\n3     ■ [閒聊] 閃耀暖暖-長得醜錯了嗎QQ http://disp.cc/b/796-bdE7\n4  ■ Re: [問卦] 蜂蜜快到期了 該怎辦？(附圖) http://disp.cc/b/79..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 1-4 Dcard熱門文章搜尋"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef dcard_f():\n    URL = 'https://www.dcard.tw/f'\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n    resp = requests.get(URL, headers=headers)\n    soup = BeautifulSoup(resp.text, 'html.parser')\n\n    content = \"\"\n    # 利用 regex 找出所有 'PostList_wrapper_' 開頭的 div\n    for index, div in enumerate(soup.find_all('div', re.compile('PostEntry_content_\\w{5}'))):\n        if index == 10:\n            return content\n        title = div.h3.text.strip()\n        excerpt = div.find_all('div')[0].text.strip()\n        href = div.parent.parent['href']\n        content += ' https://www.dcard.tw{}\\n'.format(href)\n    return content\n\ndcard_f().split(\"\\n\")",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "[' https://www.dcard.tw/f/disaster/p/231113837-各地災情回報-[4／18-13:01-地震快報]',\n ' https://www.dcard.tw/f/funny/p/231106081-被媽媽衝康，差點被警察抓去勒戒。',\n ' https://www.dcard.tw/f/trending/p/231106354-普悠瑪駕駛被撤銷駕照終身禁考',\n ' https://www.dcard.tw/f/food/p/231106558-跟男友同居一年，兩人胖十五公斤！-＃自己煮',\n ' https://www.dcard.tw/f/girl/p/231105751-＃求解-換包包還是換男友？',\n ' https://www.dcard.tw/f/entertainer/p/231107410-更）超親民的議員',\n ' https://www.dcard.tw/f/mood/p/231104628-幹破林娘胰臟癌',\n ' https://www.dcard.tw/f/entertainer/p/231109455-辜莞允散播閨蜜裸照',\n ' https://www.dcard.tw/f/vehicle/p/231104856-還是有人不願意乖乖兩段式左轉',\n ' https://www.dcard.tw/f/relationship/p/231098894-你身邊也有難搞的公主們嗎？「等等吃什麼」的世紀難題，解法底加！ft.foodpanda',\n '']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dcard_df = pd.DataFrame(dcard_f().split(\"\\n\"))\ndcard_df",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.dcard.tw/f/disaster/p/231113837-各...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.dcard.tw/f/funny/p/231106081-被媽媽衝...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.dcard.tw/f/trending/p/231106354-普...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.dcard.tw/f/food/p/231106558-跟男友同居...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.dcard.tw/f/girl/p/231105751-＃求解-換...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://www.dcard.tw/f/entertainer/p/23110741...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://www.dcard.tw/f/mood/p/231104628-幹破林娘胰臟癌</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>https://www.dcard.tw/f/entertainer/p/23110945...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>https://www.dcard.tw/f/vehicle/p/231104856-還是...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>https://www.dcard.tw/f/relationship/p/2310988...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                    0\n0    https://www.dcard.tw/f/disaster/p/231113837-各...\n1    https://www.dcard.tw/f/funny/p/231106081-被媽媽衝...\n2    https://www.dcard.tw/f/trending/p/231106354-普...\n3    https://www.dcard.tw/f/food/p/231106558-跟男友同居...\n4    https://www.dcard.tw/f/girl/p/231105751-＃求解-換...\n5    https://www.dcard.tw/f/entertainer/p/23110741...\n6     https://www.dcard.tw/f/mood/p/231104628-幹破林娘胰臟癌\n7    https://www.dcard.tw/f/entertainer/p/23110945...\n8    https://www.dcard.tw/f/vehicle/p/231104856-還是...\n9    https://www.dcard.tw/f/relationship/p/2310988...\n10                                                   "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 1-5 蘋果日報即時新聞"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def apple_news():\n    target_url = 'https://tw.appledaily.com/new/realtime'\n    print('Start parsing appleNews....')\n    rs = requests.session()\n    res = rs.get(target_url, verify=False)\n    soup = BeautifulSoup(res.text, 'html.parser')\n    content = \"\"\n    for index, data in enumerate(soup.select('.rtddt a'), 0):\n        if index == 5:\n            return content\n        link = data['href']\n        content += ' {}\\n'.format(link)\n    return content\n\napple_news().split(\"\\n\")",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Start parsing appleNews....\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "[' https://tw.news.appledaily.com/international/realtime/20190418/1552470/',\n ' https://tw.news.appledaily.com/international/realtime/20190418/1552676/',\n ' https://tw.lifestyle.appledaily.com/gadget/realtime/20190418/1552401/',\n ' https://tw.finance.appledaily.com/realtime/20190418/1552750/',\n ' https://tw.news.appledaily.com/politics/realtime/20190418/1552749/',\n '']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def movie():\n    target_url = 'http://www.atmovies.com.tw/movie/next/0/'\n    print('Start parsing movie ...')\n    rs = requests.session()\n    res = rs.get(target_url, verify=False)\n    res.encoding = 'utf-8'\n    soup = BeautifulSoup(res.text, 'html.parser')\n    content = \"\"\n    for index, data in enumerate(soup.select('ul.filmNextListAll a')):\n        if index == 20:\n            return content\n        title = data.text.replace('\\t', '').replace('\\r', '')\n        link = \"http://www.atmovies.com.tw\" + data['href']\n        content += '{} {} '.format(title, link)\n    return content\n\nmovie().split(\"\\n\")",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Start parsing movie ...\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "['',\n '刀說異數：第14章 http://www.atmovies.com.tw/movie/fwcn77479124/ ',\n '牛津解密 http://www.atmovies.com.tw/movie/fpen55932728/ ',\n '原本以為只是手機掉了 http://www.atmovies.com.tw/movie/fsjp98531044/ ',\n '希特勒對畢卡索：被奪取的名畫 http://www.atmovies.com.tw/movie/fhit98016764/ ',\n '淪落人 http://www.atmovies.com.tw/movie/fscn38497794/ ',\n '上流世界 http://www.atmovies.com.tw/movie/flit26748466/ ',\n '失控班！ http://www.atmovies.com.tw/movie/fsfr37175992/ ',\n '就是要妳愛上我 http://www.atmovies.com.tw/movie/fljp88718066/ ',\n '電影刀劍亂舞 http://www.atmovies.com.tw/movie/fejp68493238/ ',\n '魔力女聲 http://www.atmovies.com.tw/movie/ften46483364/ ',\n '愛上太空女神 http://www.atmovies.com.tw/movie/faen65215088/ ',\n '噬魂實驗 http://www.atmovies.com.tw/movie/fden44685940/ ',\n 'Aqours ASIA TOUR 2019 in Seoul http://www.atmovies.com.tw/movie/fljp93558479/ ',\n '刀說異數：第15章 http://www.atmovies.com.tw/movie/fwcn77479125/ ',\n '復仇者聯盟4：終局之戰 http://www.atmovies.com.tw/movie/faen64154796/ ',\n '我唾棄你的墳墓3 http://www.atmovies.com.tw/movie/fien84530884/ ',\n '卡拉瓦喬：靈魂與血肉之軀 http://www.atmovies.com.tw/movie/fcit97955970/ ',\n '三夫 http://www.atmovies.com.tw/movie/ftcn29076570/ ',\n '幸福的拉札洛 http://www.atmovies.com.tw/movie/flit66752992/ ',\n '三更半夜居然要吃香蕉？ http://www.atmovies.com.tw/movie/fajp99010228/ ']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 1-6 油價查詢"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def oil_price():\n    target_url = 'https://gas.goodlife.tw/'\n    rs = requests.session()\n    res = rs.get(target_url, verify=False)\n    soup = BeautifulSoup(res.text, 'html.parser')\n    title = soup.select('#main')[0].text.replace('\\n', '').split('(')[0].replace('\\n', ',')\n    gas_price = soup.select('#gas-price')[0].text.replace('\\n\\n\\n', '').replace(' ', '')\n    cpc = soup.select('#cpc')[0].text.replace(' ', '')\n    content = '{} {} {}'.format(title, gas_price, cpc)\n\n\n    return content\n\noil_price().replace('\\n', '')",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'最後更新時間: 2019-04-18 15:14  柴油預計調整:-0.0元中油累計吸0.1元,若不列入計算,應調整:+0.8元受到鄰國油價影響，下週一2019年04月22日起,預計汽油每公升:漲0.5元 今日中油油價92:27.995油價:29.498:31.4柴油:26.7'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def technews():\n    target_url = 'https://technews.tw/'\n    print('Start parsing movie ...')\n    rs = requests.session()\n    res = rs.get(target_url, verify=False)\n    res.encoding = 'utf-8'\n    soup = BeautifulSoup(res.text, 'html.parser')\n    content = \"\"\n\n    for index, data in enumerate(soup.select('article div h1.entry-title a')):\n        if index == 5:\n            return content\n        title = data.text\n        link = data['href']\n        content += '{} {}\\n'.format(title, link)\n    return content\n\ntechnews().split(\"\\n\")",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Start parsing movie ...\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "['大麻漢堡來了，4/20 大麻日美速食店限日嘗鮮 https://technews.tw/2019/04/18/rocky-mountain-high-cheeseburger-delight/',\n '英特爾新顯卡或用三星記憶體？高層訪南韓，揣測滿天飛 https://technews.tw/2019/04/18/intel-gpu-samsung-memory/',\n '台積電 2019 年第 1 季 EPS 2.37 元符合預期，地震沒有造成任何災情 https://finance.technews.tw/2019/04/18/tsmc-2019q1-financial-meeting/',\n 'Facebook 呼籲不要用最終點擊評估行銷成效，而是總業績增幅 https://technews.tw/2019/04/18/facebook-claim-retails-should-not-only-judge-by-clicks-but-by-total-performance-increase/',\n '花蓮強震，台電：核一二廠正常運轉 https://technews.tw/2019/04/18/taipower-nuclear-power-plant-safe/',\n '']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### reference\n\n  - [line-bot-tutorial](https://github.com/willismax/line-bot-tutorial)\n  - [Python 網路爬蟲與資料分析入門實戰 ](https://www.tenlong.com.tw/products/9789864343386)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}