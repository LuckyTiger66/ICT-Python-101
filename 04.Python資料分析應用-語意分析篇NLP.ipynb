{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 04.Python資料分析入門-語意分析篇NLP"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 04-1 基本語意分析-以模組舉例\n- 以[手把手教你如何用 Python 做情感分析](https://www.itread01.com/articles/1498721884.html)為例"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 04-1-1 英文為例"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#安裝相關套件\n!pip install snownlp\n!pip install -U textblob\n!python -m textblob.download_corpora",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: snownlp in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.12.3)\nRequirement already up-to-date: textblob in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.15.3)\nRequirement already satisfied, skipping upgrade: nltk>=3.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from textblob) (3.3)\nRequirement already satisfied, skipping upgrade: six in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.11.0)\n[nltk_data] Downloading package brown to /home/nbuser/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n[nltk_data] Downloading package punkt to /home/nbuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/nbuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/nbuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package conll2000 to /home/nbuser/nltk_data...\n[nltk_data]   Package conll2000 is already up-to-date!\n[nltk_data] Downloading package movie_reviews to\n[nltk_data]     /home/nbuser/nltk_data...\n[nltk_data]   Package movie_reviews is already up-to-date!\nFinished.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text = \"I am happy today. I feel sad today.\"",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from textblob import TextBlob\n\nblob = TextBlob(text)\nblob.sentences",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "[Sentence(\"I am happy today.\"), Sentence(\"I feel sad today.\")]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#情感極性的變化範圍是[-1, 1]，-1代表完全負面，1代表完全正面。\nprint(blob.sentences[0].sentiment)\nprint(blob.sentences[1].sentiment)\nprint(blob.sentiment)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Sentiment(polarity=0.8, subjectivity=1.0)\nSentiment(polarity=-0.5, subjectivity=1.0)\nSentiment(polarity=0.15000000000000002, subjectivity=1.0)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 04-1-2 中文為例\n- 使用SnowNLP: http://t.cn/8kf1c3p"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text = u\"我今天很快樂。我今天很憤怒。\" #u指文本的編碼是Unicode",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from snownlp import SnowNLP\n\ns = SnowNLP(text)\ns.sentences",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "['我今天很快樂', '我今天很憤怒']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#SnowNLP的情感分析取值，表達的是“這句話代表正面情感的概率”。\nprint(SnowNLP(s.sentences[0]).sentiments)\nprint(SnowNLP(s.sentences[1]).sentiments)\nprint(s.sentiments)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.9268071116367116\n0.1702660762575916\n0.7005413250638438\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text = u'''\n台中市雷姓男子去年10月間在西區公益路、大墩路的工地喝酒後，騎車上路，遭警方盤查後，酒測值超標為每公升0.70毫克，他遭警方依公共危險罪嫌送辦，檢方聲請簡易判決處刑，法官判他4月徒刑、得易科罰金，但他今年2月要報到執行時，檢方命他不得易科，需入監服刑，他向台中地院聲明異議，法官審理後認為，雷在2016至2018年間連續3度酒駕，前二次一次是緩起訴、另次則是易科罰金，但此次又被查獲，已是第三次，認為他漠視法律，不矯正難收矯正之效，駁回雷聲明異議，判雷要關。\n判決書指出，雷姓男子（41歲）去年10月間酒後騎車被查獲，酒測值為每公升0.70毫克，台中地院依公共危險罪，簡易判決處刑4月，得易科罰金12萬元，不過雷在今年2月到台中地檢署報到執行時，檢方諭令他不得易科，需入監服刑，他不服向台中地院聲明異議。\n\n雷辯稱，判決書上明寫可易科罰金，為何檢方堅持要讓他去服刑，而且他已離婚是單親家庭，有未成年子女要撫養，家境貧寒是中低收入戶，更是家中主要的經濟支柱，希望法官撤銷檢察官不得易科的執行指揮處分，准予讓他易科罰金。\n\n台中地院法官審理後認為，雖然法律有規定，本刑5年以下，宣告6月以下徒刑者， 得易科罰金，不過但書是「難收矯正之效或難以維持法秩序者，不在此限」，易科罰金的易刑處分，應否准許，依照《刑事訴訟法》第457條規定，由檢察官就是否准予受刑人易科罰金，有無但書情況，由檢方查明認定並指揮執行。\n\n法官指出，雷在2016年酒駕被查獲後，獲緩起訴處分，2017年又被查獲酒駕，當時被判3月徒刑，得易科9萬元，但他2018年又喝酒上路，顯示雷沒有因前兩次遭查獲的前例，而有所警惕，且去年被查獲時，是在喝完啤酒不久就騎車上路，顯然極度漠視法令，其行為對社會法秩序之危害重大，因此認定檢方的處分無不妥，駁回雷聲明異議。\n'''",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "s = SnowNLP(text)\n#s.sentences[0]\ns.sentiments",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "0.0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 04-2 基本語意分析-以PTT電影版透過機械學習方式舉例\n- 以下來自[Python 網路爬蟲與資料分析入門實戰 ](https://www.tenlong.com.tw/products/9789864343386)\n- 2019年10月出版的新書，裡面很多台灣在地的爬蟲應用教學，[github](https://github.com/willismax/py-scraping-analysis-book)也有該書的程式碼，可以先試試看。\n- 此例為以PTT電影版關鍵字輸入影片名稱做舉例，以「好雷、負雷」做分類，以機械學習方式，將各文章內文詞斷詞，並預測分類結果"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport re\nimport csv\nfrom bs4 import BeautifulSoup\n\n\nPTT_URL = 'https://www.ptt.cc'\n\n\ndef get_articles(url):\n    resp = requests.get(\n        url=url,\n        cookies={'over18': '1'}  # 告知 Server 已回答過滿 18 歲的問題\n    )\n    soup = BeautifulSoup(resp.text, 'html5lib')\n    prev_link = soup.find('div', 'btn-group-paging').find_all('a')[1]\n    # 若 <a> 有 href 屬性, 代表有上一頁的超連結\n    prev_link = prev_link['href'] if 'href' in prev_link.attrs else None\n\n    # 巡覽每一篇文章所在區塊\n    positive = []\n    negative = []\n    for div in soup.find_all('div', 'r-ent'):\n        href = div.find('div', 'title').a['href']\n        title = div.find('div', 'title').text.strip()\n        # 若標題為 [] 開頭, e.g., [好雷] 星際大戰八-各種元素集於一身\n        if re.match('\\[.*\\]', title):\n            tag = re.match('\\[.*\\]', title).group(0)\n            # 標籤內含'好'為好評; 含'負'或'爛'為負評\n            if '好' in tag:\n                positive.append([title, href])\n            if '爛' in tag or '負' in tag:\n                negative.append([title, href])\n    return prev_link, positive, negative\n\n\nif __name__ == '__main__':\n    start_url = PTT_URL + '/bbs/movie/search?q=黑豹'\n    positive_posts, negative_posts = [], []\n    prev_link, pos, neg = get_articles(start_url)\n    positive_posts += pos\n    negative_posts += neg\n    while prev_link:\n        url = PTT_URL + prev_link\n        prev_link, pos, neg = get_articles(url)\n        positive_posts += pos\n        negative_posts += neg\n    print(len(positive_posts), positive_posts[:3])\n    print(len(negative_posts), negative_posts[:3])\n\n    with open('./data/mov_pos.csv', 'w', encoding='utf-8', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['title', 'href'])\n        writer.writerows(positive_posts)\n\n    with open('./data/mov_neg.csv', 'w', encoding='utf-8', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['title', 'href'])\n        writer.writerows(negative_posts)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "60 [['[好雷]  黑豹 --其實蠻好看的', '/bbs/movie/M.1552276420.A.F6F.html'], ['[好雷?] 黑豹 自慰片的新高度', '/bbs/movie/M.1545317279.A.EFC.html'], ['[二刷好雷] 水行俠真的不是黑豹', '/bbs/movie/M.1545065816.A.46A.html']]\n27 [['[負雷]黑豹-失衡的烏托邦', '/bbs/movie/M.1529245622.A.AF5.html'], ['[負雷] 四不像的黑豹', '/bbs/movie/M.1527918611.A.56C.html'], ['[微負雷] 黑豹有點讓人失望....', '/bbs/movie/M.1527839684.A.EF0.html']]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import csv\nimport requests\nimport re\nimport json\nimport time\nfrom bs4 import BeautifulSoup\n\n\nPTT_URL = 'https://www.ptt.cc'\n\n\ndef sanitize(txt):\n    # 保留英數字, 中文 (\\u4e00-\\u9fa5) 及中文標點, 部分特殊符號\n    # http://ubuntu-rubyonrails.blogspot.com/2009/06/unicode.html\n    expr = re.compile('[^\\u4e00-\\u9fa5。；，：“”（）、？「」『』【】\\s\\w:/\\-.()]')  # ^ 表示\"非括號內指定的字元\"\n    txt = re.sub(expr, '', txt)\n    txt = re.sub('[。；，：“”（）、？「」『』【】:/\\-_.()]', ' ', txt)  # 用空白取代中英文標點\n    txt = re.sub('(\\s)+', ' ', txt)  # 用單一空白取代多個換行或 tab 符號\n    txt = txt.replace('--', '')\n    txt = txt.lower()  # 英文字轉為小寫\n    return txt\n\n\ndef get_post(url):\n    resp = requests.get(\n        url=url,\n        cookies={'over18': '1'}  # 告知 Server 已回答過滿 18 歲的問題\n    )\n    soup = BeautifulSoup(resp.text, 'html5lib')\n    main_content = soup.find('div', id='main-content')\n\n    # 把非本文的部份 (標題區及推文區) 移除\n    # 移除標題區塊\n    for meta in main_content.find_all('div', 'article-metaline'):\n        meta.extract()\n    for meta in main_content.find_all('div', 'article-metaline-right'):\n        meta.extract()\n    # 移除推文區塊\n    for push in main_content.find_all('div', 'push'):\n        push.extract()\n\n    parsed = []\n    for txt in main_content.stripped_strings:\n        # 移除 '※ 發信站:', '--' 開頭, 及本文區最後一行文章網址部份\n        if txt[0] == '※' or txt[:2] == '--' or url in txt:\n            continue\n        txt = sanitize(txt)\n        if txt:\n            parsed.append(txt)\n    return ' '.join(parsed)\n\n\ndef get_article_body(csv_file):\n    id_to_body = {}\n    with open(csv_file, 'r', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            print('處理', row['title'], row['href'])\n            title = ' '.join(row['title'].split(']')[1:])\n            title = sanitize(title)\n            body = get_post(PTT_URL + row['href'])\n            id_to_body[row['href']] = title + ' ' + body  # 以文章超連結為 key, 標題 + 本文為 value\n            time.sleep(1)  # 放慢爬蟲速度\n    return id_to_body\n\n\nif __name__ == '__main__':\n    d1 = get_article_body('./data/mov_pos.csv')\n    d2 = get_article_body('./data/mov_neg.csv')\n    id_to_body = {**d1, **d2}  # 將兩個 dict 合併為一個\n    with open('./data/id_to_body.json', 'w', encoding='utf-8') as f:\n        json.dump(id_to_body, f, indent=2, ensure_ascii=False)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "處理 [好雷]  黑豹 --其實蠻好看的 /bbs/movie/M.1552276420.A.F6F.html\n處理 [好雷?] 黑豹 自慰片的新高度 /bbs/movie/M.1545317279.A.EFC.html\n處理 [二刷好雷] 水行俠真的不是黑豹 /bbs/movie/M.1545065816.A.46A.html\n處理 [好雷] 盲點：關於《黑豹》的奧克蘭也關於你我的故事 /bbs/movie/M.1538060300.A.8FD.html\n處理 [好雷] 瘋狂亞洲富豪─絕不是新加坡黑豹 /bbs/movie/M.1536676591.A.C8F.html\n處理 [微好雷]《雷神索爾3諸神黃昏》＆《黑豹》 /bbs/movie/M.1536217925.A.B6E.html\n處理 [好雷] 比黑豹好看的蟻人與黃蜂女 /bbs/movie/M.1531217457.A.6C8.html\n處理 [好雷]黑豹 — 符合台灣政治的隱喻分析 /bbs/movie/M.1525369009.A.CFA.html\n處理 [好雷] 黑豹：一部政治寓言 /bbs/movie/M.1521128014.A.19B.html\n處理 [好雷]黑豹，好看但可惜的反派 /bbs/movie/M.1520467155.A.8E5.html\n處理 [好雷] 黑豹心得 /bbs/movie/M.1519920385.A.14A.html\n處理 [ 好雷] 唯一缺憾的黑豹 /bbs/movie/M.1519908058.A.B99.html\n處理 [好雷] 黑豹 感想 微負評 /bbs/movie/M.1519841715.A.3BF.html\n處理 [核心好雷] 黑豹-科技與部落的反差萌 人權與人道議題 /bbs/movie/M.1519812809.A.DC3.html\n處理 [普好雷] 立體的世界，被一掌拍平，淺談【黑豹】 /bbs/movie/M.1519787493.A.BFD.html\n處理 [有意見好雷] 比上沒得比，比下有餘的黑豹 /bbs/movie/M.1519734682.A.979.html\n處理 [好雷] 黑豹 ~ 屬於黑人的童話故事 /bbs/movie/M.1519618436.A.EA0.html\n處理 [ 好 雷] 黑豹 /bbs/movie/M.1519572758.A.D3C.html\n處理 [好雷]黑豹 王者的抉擇 /bbs/movie/M.1519544126.A.E20.html\n處理 [好雷] 黑豹就真的很好看咩~ /bbs/movie/M.1519356550.A.A17.html\n處理 [ 普好雷] 黑豹 /bbs/movie/M.1519142286.A.7CD.html\n處理 [好雷] 黑豹 /bbs/movie/M.1519070229.A.DE9.html\n處理 [好雷] 黑豹：王者路大不易 /bbs/movie/M.1519042966.A.803.html\n處理 [微好雷]《黑豹》　春秋五霸的基本套路 /bbs/movie/M.1518991149.A.BDD.html\n處理 [好雷]黑豹 不太一樣的超級英雄 /bbs/movie/M.1518963410.A.A2E.html\n處理 [好雷] 黑豹 其實我比較喜歡反派@@ /bbs/movie/M.1518939706.A.D48.html\n處理 [好雷] 黑豹 Black Panther，非洲未來主義 /bbs/movie/M.1518893529.A.3AD.html\n處理 [好雷]  黑豹： 智者造橋，愚者築牆 /bbs/movie/M.1518860486.A.B45.html\n處理 [微好雷] 黑豹的電影配樂 /bbs/movie/M.1518848376.A.BBB.html\n處理 [好無雷] 黑豹 /bbs/movie/M.1518802967.A.D32.html\n處理 [好雷] 黑豹  沒有大家說的那麼糟啦 /bbs/movie/M.1518793606.A.036.html\n處理 [好雷] 黑豹 /bbs/movie/M.1518778797.A.C52.html\n處理 [普好雷] 黑豹:Do you know da way? /bbs/movie/M.1518769142.A.229.html\n處理 [普好雷] 黑豹 來談談角色動機吧 /bbs/movie/M.1518703695.A.0DC.html\n處理 [好雷]YOU SHOW OFF?——《黑豹》無&有雷推薦 /bbs/movie/M.1518641125.A.57A.html\n處理 [普好雷] 覺得黑豹的編劇陷入一種兩難的情況 /bbs/movie/M.1518632731.A.55E.html\n處理 [好笑雷] 黑豹 /bbs/movie/M.1518627430.A.ADF.html\n處理 [好雷] 黑豹 耳目一新的英雄電影 /bbs/movie/M.1518617014.A.223.html\n處理 [好雷] 黑豹 最沒有在看爽的漫威片 /bbs/movie/M.1518584186.A.CA8.html\n處理 [偏好雷] 看完黑豹我再重看一次預告片發現... /bbs/movie/M.1518541335.A.C93.html\n處理 [好雷] 黑豹 國王成長日記 /bbs/movie/M.1518538495.A.43A.html\n處理 [好雷] 黑豹 世界觀科技感超讚 但故事有些許bug /bbs/movie/M.1518537228.A.F8C.html\n處理 [超爆幹好雷] 黑豹-名副其實漫威最佳 /bbs/movie/M.1518536561.A.C1C.html\n處理 [普好雷] 黑豹 /bbs/movie/M.1518535690.A.7CD.html\n處理 [好雷]【黑豹】非洲先進文明卓然而立 /bbs/movie/M.1518521887.A.244.html\n處理 [普好雷] 充滿新風格的黑豹 /bbs/movie/M.1518517571.A.DD1.html\n處理 [好雷] 不太懂有關黑豹反派的幾件事情 /bbs/movie/M.1518512928.A.747.html\n處理 [好雷] 小細節怪怪的黑豹 /bbs/movie/M.1518511893.A.636.html\n處理 [好雷] 黑豹 /bbs/movie/M.1518507928.A.ABD.html\n處理 [好無雷] 黑豹 /bbs/movie/M.1518505340.A.C9A.html\n處理 [好雷] 黑豹觀後討論 /bbs/movie/M.1518501262.A.9AC.html\n處理 [普好雷] 黑豹 優秀的漫威宇宙擴展片 /bbs/movie/M.1518500618.A.932.html\n處理 [極好無雷]  這就是我要的黑豹！ /bbs/movie/M.1518499054.A.561.html\n處理 [ 好無雷] 黑豹 絕對值得一看 /bbs/movie/M.1518496440.A.BE1.html\n處理 [好無雷]  大推推黑豹電影 /bbs/movie/M.1518495524.A.882.html\n處理 [好雷] 黑豹，劇情普通，美術太完美 /bbs/movie/M.1518495424.A.F0B.html\n處理 [好雷] 黑豹 /bbs/movie/M.1518494060.A.826.html\n處理 [ 好雷] 美國隊長3 黑豹疑問 /bbs/movie/M.1462012717.A.D23.html\n處理 [好雷]美隊3-關於黑豹以及各英雄的立場 /bbs/movie/M.1461921066.A.E77.html\n處理 [好雷] 美國隊長3  黑豹家世 /bbs/movie/M.1461748087.A.515.html\n處理 [負雷]黑豹-失衡的烏托邦 /bbs/movie/M.1529245622.A.AF5.html\n處理 [負雷] 四不像的黑豹 /bbs/movie/M.1527918611.A.56C.html\n處理 [微負雷] 黑豹有點讓人失望.... /bbs/movie/M.1527839684.A.EF0.html\n處理 [負雷] 是不是有精神分裂的黑豹 /bbs/movie/M.1526734538.A.5E2.html\n處理 [負雷] 黑豹 /bbs/movie/M.1520322497.A.E24.html\n處理 [負雷]黑豹  最差漫威電影 /bbs/movie/M.1519931938.A.207.html\n處理 [  微負雷] 黑豹 /bbs/movie/M.1519721961.A.471.html\n處理 [負雷] 黑豹 Black Panther，暴力與分享 /bbs/movie/M.1518961786.A.79E.html\n處理 [  負雷] 隨便拍拍隨便買單的「黑豹」 /bbs/movie/M.1518934190.A.F7B.html\n處理 [負雷] 只有政治正確的  黑豹 /bbs/movie/M.1518809750.A.4E0.html\n處理 [負雷]黑豹：除了美術視覺，其餘毫無魅力 /bbs/movie/M.1518808279.A.FC9.html\n處理 [睡負無雷] 看黑豹看到睡著 /bbs/movie/M.1518774686.A.889.html\n處理 [小負雷] 黑豹-請修邊幅可以嗎?(內有雷) /bbs/movie/M.1518761310.A.05C.html\n處理 [爛無雷] 千萬不要期待的黑豹 /bbs/movie/M.1518758578.A.8F0.html\n處理 [普負雷] 輸不起的黑豹 /bbs/movie/M.1518714311.A.957.html\n處理 [  負雷] 黑豹-鋪陳復3的跳板 /bbs/movie/M.1518684255.A.489.html\n處理 [ 負雷] 黑豹 /bbs/movie/M.1518670825.A.A31.html\n處理 [普負雷] 黑豹出戲點 /bbs/movie/M.1518642702.A.497.html\n處理 [負雷] 黑豹特遣隊 /bbs/movie/M.1518609915.A.835.html\n處理 [負雷] 家天下黑豹 /bbs/movie/M.1518596627.A.3E0.html\n處理 [負雷] 失望的黑豹(補個優點) /bbs/movie/M.1518577527.A.4BB.html\n處理 [負雷] 真的過譽的黑豹......... /bbs/movie/M.1518536086.A.B1E.html\n處理 [負雷] 黑豹天下 /bbs/movie/M.1518534403.A.ECB.html\n處理 [  負雷] 讓人失望的黑豹 /bbs/movie/M.1518529744.A.586.html\n處理 [普負雷]  一片歐罵罵的黑豹 /bbs/movie/M.1518513719.A.462.html\n處理 [微負雷] 黑豹 相較其他marvel片有點可惜 /bbs/movie/M.1518510319.A.1DC.html\n處理 [負雷]黑豹 /bbs/movie/M.1518495315.A.E27.html\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install jieba",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: jieba in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.39)\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install sklearn\import json\nimport csv\nimport jieba\nimport random\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score\n\njieba.set_dictionary('./data/dict.txt.big')  # 對繁體中文斷詞較準確的字典檔\n\n\ndef load_data(a_csv, b_json, label):\n    a_ids = []\n    with open(a_csv, 'r', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            a_ids.append(row['href'])\n    with open(b_json, 'r', encoding='utf-8') as f:\n        id_to_body = json.load(f)\n    data = []\n    for a_id in a_ids:\n        tokenized_post = []\n        txt = id_to_body[a_id]\n        for sent in txt.split():  # 將文章以空白隔開\n            # 斷詞後的結果, 若非空白且長度為 2 以上, 則列入詞庫\n            filtered = [t for t in jieba.cut(sent) if t.split() and len(t) > 1]\n            tokenized_post += filtered\n        data.append((tokenized_post, label))\n    return data\n\n\nif __name__ == '__main__':\n    pos_data = load_data('./data/mov_pos.csv', './data/id_to_body.json', '正評')\n    neg_data = load_data('./data/mov_neg.csv', './data/id_to_body.json', '負評')\n\n    '''\n    # 印出正評與負評文章的前幾個字, 確認資料無誤\n    for post, label in pos_data[:3]:\n        print(post[:5], label)\n    for post, label in neg_data[:3]:\n        print(post[:5], label)\n    '''\n\n    # 打亂資料順序\n    random.seed(42)\n    random.shuffle(pos_data)\n    random.shuffle(neg_data)\n\n    x_train, y_train, x_test, y_test = [], [], [], []\n    # 前 22 筆資料 (及答案) 放入 training set\n    # 建立資料時要用空白將斷好的詞重新連成一個字串, 以便之後使用 scikit-learn 建立字典並轉換文字資料為向量\n    for i in range(10):\n        x_train.append(' '.join(pos_data[i][0]))\n        x_train.append(' '.join(neg_data[i][0]))\n        y_train.append(pos_data[i][1])\n        y_train.append(neg_data[i][1])\n    # 最後 5 筆資料 (及答案) 放入 testing set\n#     for i in range(5, len(pos_data)):\n    for i in range(10, 27):\n        x_test.append(' '.join(pos_data[i][0]))\n        x_test.append(' '.join(neg_data[i][0]))\n        y_test.append(pos_data[i][1])\n        y_test.append(neg_data[i][1])\n\n    vectorizer = CountVectorizer()\n    x_train = vectorizer.fit_transform(x_train)\n    transformer = TfidfTransformer()\n    x_train = transformer.fit_transform(x_train)\n    clf = SGDClassifier(random_state=42)\n    clf.fit(x_train, y_train)\n    x_test = vectorizer.transform(x_test)\n    x_test = transformer.transform(x_test)\n    y_pred = clf.predict(x_test)\n    print('預測結果:', list(y_pred))\n    print('正確答案:', y_test)\n    print('正確率:', accuracy_score(y_test, y_pred))\n\n    # 測試自己輸入的句子\n    sentences = [\n        '我 覺得 這部 電影 還 不錯',\n        '這部 片 應該 可以 更好 才對'\n    ]\n    analyze = vectorizer.build_analyzer()\n    print(analyze(sentences[0]))\n    print(analyze(sentences[1]))\n\n    custom_data = transformer.transform(vectorizer.transform(sentences))\n    print(clf.predict(custom_data))",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Building prefix dict from /home/nbuser/library/lesson/data/dict.txt.big ...\nLoading model from cache /tmp/jieba.u863534f77a5b7aa5dc55e7aac03546ba.cache\nLoading model cost 7.137 seconds.\nPrefix dict has been built succesfully.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "預測結果: ['正評', '負評', '正評', '正評', '負評', '負評', '負評', '正評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '正評', '正評', '負評', '負評', '負評', '負評', '正評', '正評', '負評', '正評', '正評', '正評', '負評', '負評', '負評', '負評', '負評', '正評', '正評']\n正確答案: ['正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評']\n正確率: 0.6470588235294118\n['覺得', '這部', '電影', '不錯']\n['這部', '應該', '可以', '更好', '才對']\n['負評' '正評']\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(neg_data)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "27"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### refecence\n- [手把手教你如何用 Python 做情感分析](https://www.itread01.com/articles/1498721884.html)\n- [Python 網路爬蟲與資料分析入門實戰 ](https://www.tenlong.com.tw/products/9789864343386)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}